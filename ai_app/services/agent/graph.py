"""Agent LangGraph â€” StateGraph ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"""

import logging
from typing import Annotated, Any, TypedDict

from langgraph.graph import END, StateGraph
from schemas.agent import IntentResult, MentorCard, MentorConditions

from services.agent.intent_router import IntentRouter
from services.agent.mentor_search import (
    build_query_text,
    check_need_more_conditions,
    compose_reply_text,
    rule_rerank,
    vector_search,
)
from services.agent.slot_filling import SlotFiller
from services.reco.embedder import get_embedder

logger = logging.getLogger(__name__)


# ============== ìƒíƒœ ì •ì˜ ==============


def _append_events(left: list[dict], right: list[dict]) -> list[dict]:
    """events í•„ë“œë¥¼ ëˆ„ì (append)í•˜ëŠ” ë¦¬ë“€ì„œ"""
    return left + right


class AgentState(TypedDict, total=False):
    """ê·¸ë˜í”„ ì „ì²´ì—ì„œ ê³µìœ ë˜ëŠ” ìƒíƒœ"""

    # ---- ì…ë ¥ ----
    message: str
    history: list[dict]
    top_k: int

    # ---- ì¤‘ê°„ ê²°ê³¼ ----
    intent_result: IntentResult
    conditions: MentorConditions
    candidates: list[dict[str, Any]]
    cards: list[MentorCard]
    reply_text: str
    need_more: str | None

    # ---- SSE ì´ë²¤íŠ¸ ëˆ„ì  ----
    events: Annotated[list[dict], _append_events]


# ============== ë…¸ë“œ í•¨ìˆ˜ ==============


async def classify_intent_node(state: AgentState) -> dict:
    """ì˜ë„ ë¶„ë¥˜ ë…¸ë“œ"""
    router = IntentRouter()
    intent_result = await router.classify(
        message=state["message"],
        history=state.get("history"),
    )
    logger.info(f"ì˜ë„ ë¶„ë¥˜: {intent_result.intent} (confidence={intent_result.confidence})")

    return {
        "intent_result": intent_result,
        "events": [{"event": "intent", "data": intent_result.model_dump()}],
    }


async def extract_conditions_node(state: AgentState) -> dict:
    """ì¡°ê±´ ì¶”ì¶œ(Slot Filling) ë…¸ë“œ"""
    filler = SlotFiller()
    conditions = await filler.extract(state["message"])

    return {
        "conditions": conditions,
        "events": [{"event": "conditions", "data": conditions.model_dump(exclude_none=True)}],
    }


async def vector_search_node(state: AgentState) -> dict:
    """ë²¡í„° ê²€ìƒ‰ ë…¸ë“œ"""
    conditions = state["conditions"]

    # ì¿¼ë¦¬ ë¹Œë“œ & ì„ë² ë”©
    query_text = build_query_text(conditions)
    embedder = get_embedder()
    query_embedding = embedder.embed_text(query_text)
    embedding_list = query_embedding.tolist()

    # ë°±ì—”ë“œ API ê²½ìœ  ë²¡í„° ê²€ìƒ‰
    candidates = await vector_search(embedding_list, top_n=50)

    if not candidates:
        return {
            "candidates": [],
            "cards": [],
            "events": [
                {
                    "event": "text",
                    "data": {"chunk": "ì¡°ê±´ì— ë§ëŠ” ë©˜í† ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì¡°ê±´ì„ ë³€ê²½í•´ì„œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”! ğŸ™"},
                },
                {"event": "done", "data": {}},
            ],
        }

    return {"candidates": candidates, "events": []}


async def rerank_node(state: AgentState) -> dict:
    """ë£° ê¸°ë°˜ ì¬ì •ë ¬ ë…¸ë“œ"""
    # í›„ë³´ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ (vector_search_nodeì—ì„œ ì´ë¯¸ done ì´ë²¤íŠ¸ ë°œìƒ)
    if not state.get("candidates"):
        return {"cards": [], "events": []}

    cards = rule_rerank(
        state["candidates"],
        state["conditions"],
        top_k=state.get("top_k", 3),
    )

    return {
        "cards": cards,
        "events": [{"event": "cards", "data": {"cards": [c.model_dump() for c in cards]}}],
    }


async def compose_reply_node(state: AgentState) -> dict:
    """ìì—°ì–´ ë©˜íŠ¸ ìƒì„± ë…¸ë“œ"""
    cards = state.get("cards", [])
    if not cards:
        return {"reply_text": "", "events": []}

    conditions = state["conditions"]
    need_more = check_need_more_conditions(conditions)
    reply_text = await compose_reply_text(conditions, cards, need_more)

    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ SSE ì²­í¬ ìƒì„±
    text_events = []
    for sentence in reply_text.split("\n"):
        if sentence.strip():
            text_events.append({"event": "text", "data": {"chunk": sentence + "\n"}})

    text_events.append({"event": "done", "data": {}})

    return {
        "reply_text": reply_text,
        "need_more": need_more,
        "events": text_events,
    }


async def handle_d2_node(state: AgentState) -> dict:
    """D2 ì§ˆë¬¸ ê°œì„  ë…¸ë“œ (ë¯¸êµ¬í˜„)"""
    msg = "ì§ˆë¬¸ ê°œì„  ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì´ì—ìš”! ğŸš§ ë©˜í†  íƒìƒ‰ì„ ì›í•˜ì‹œë©´ ì¡°ê±´ì„ ë§ì”€í•´ì£¼ì„¸ìš”."
    return {
        "reply_text": msg,
        "events": [
            {"event": "text", "data": {"chunk": msg}},
            {"event": "done", "data": {}},
        ],
    }


async def handle_d3_node(state: AgentState) -> dict:
    """D3 AIë©˜í†  ëŒ€í™” ë…¸ë“œ (ë¯¸êµ¬í˜„)"""
    msg = "AI ë©˜í†  ëŒ€í™” ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì´ì—ìš”! ğŸš§ ë©˜í†  íƒìƒ‰ì„ ì›í•˜ì‹œë©´ ì¡°ê±´ì„ ë§ì”€í•´ì£¼ì„¸ìš”."
    return {
        "reply_text": msg,
        "events": [
            {"event": "text", "data": {"chunk": msg}},
            {"event": "done", "data": {}},
        ],
    }


# ============== ì¡°ê±´ë¶€ ë¼ìš°íŒ… ==============


def route_by_intent(state: AgentState) -> str:
    """ì˜ë„ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¥¼ ê²°ì •"""
    intent = state["intent_result"].intent
    if intent == "D1":
        return "extract_conditions"
    elif intent == "D2":
        return "handle_d2"
    else:
        return "handle_d3"


# ============== ê·¸ë˜í”„ ë¹Œë“œ ==============


def build_agent_graph() -> StateGraph:
    """Agent StateGraphë¥¼ êµ¬ì„±í•˜ê³  ì»´íŒŒì¼í•œë‹¤."""
    graph = StateGraph(AgentState)

    # ë…¸ë“œ ë“±ë¡
    graph.add_node("classify_intent", classify_intent_node)
    graph.add_node("extract_conditions", extract_conditions_node)
    graph.add_node("vector_search", vector_search_node)
    graph.add_node("rerank", rerank_node)
    graph.add_node("compose_reply", compose_reply_node)
    graph.add_node("handle_d2", handle_d2_node)
    graph.add_node("handle_d3", handle_d3_node)

    # ì—£ì§€ ì—°ê²°
    graph.set_entry_point("classify_intent")
    graph.add_conditional_edges(
        "classify_intent",
        route_by_intent,
        {
            "extract_conditions": "extract_conditions",
            "handle_d2": "handle_d2",
            "handle_d3": "handle_d3",
        },
    )
    graph.add_edge("extract_conditions", "vector_search")
    graph.add_edge("vector_search", "rerank")
    graph.add_edge("rerank", "compose_reply")
    graph.add_edge("compose_reply", END)
    graph.add_edge("handle_d2", END)
    graph.add_edge("handle_d3", END)

    return graph.compile()


# ì‹±ê¸€í†¤
_compiled_graph = None


def get_agent_graph():
    """ì»´íŒŒì¼ëœ ê·¸ë˜í”„ ì‹±ê¸€í†¤"""
    global _compiled_graph
    if _compiled_graph is None:
        _compiled_graph = build_agent_graph()
        logger.info("âœ… Agent LangGraph ì»´íŒŒì¼ ì™„ë£Œ")
    return _compiled_graph
