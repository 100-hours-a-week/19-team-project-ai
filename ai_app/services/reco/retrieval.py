"""ë©˜í†  ê²€ìƒ‰ ëª¨ë“ˆ - í•„í„°ë§ + ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ"""

import logging
from dataclasses import dataclass
from typing import Any

from adapters.backend_client import BackendAPIClient, get_backend_client
from adapters.db_client import VectorSearchClient, get_vector_search_client
from opentelemetry import trace

from services.reco.embedder import ProfileEmbedder, get_embedder

logger = logging.getLogger(__name__)
tracer = trace.get_tracer(__name__)

# í•„í„°ë§ fallback ì„ê³„ê°’
MIN_CANDIDATES_FOR_JOB_FILTER = 5


@dataclass
class MentorCandidate:
    """ë©˜í†  í›„ë³´ ë°ì´í„°"""

    user_id: int
    nickname: str
    introduction: str
    company_name: str | None
    verified: bool
    rating_avg: float
    rating_count: int
    response_rate: float
    skills: list[str]
    jobs: list[str]
    similarity_score: float
    last_active_at: str | None
    filter_type: str | None = None
    ground_truth: dict | None = None
    # ë‚´ë¶€ í•„í„°ë§ìš©
    _job_matched: bool = False
    _skill_matched: bool = False

    def to_dict(self, include_internal: bool = False) -> dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        result = {
            "user_id": self.user_id,
            "nickname": self.nickname,
            "company_name": self.company_name,
            "verified": self.verified,
            "rating_avg": self.rating_avg,
            "rating_count": self.rating_count,
            "response_rate": self.response_rate,
            "skills": self.skills,
            "jobs": self.jobs,
            "introduction": self.introduction,
            "similarity_score": self.similarity_score,
            "filter_type": self.filter_type,
            "ground_truth": self.ground_truth,
            "last_active_at": self.last_active_at,
        }
        if include_internal:
            result["_job_matched"] = self._job_matched
            result["_skill_matched"] = self._skill_matched
        return result


class MentorRetriever:
    """ë©˜í†  ê²€ìƒ‰ - í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ í™œìš©"""

    def __init__(
        self,
        backend_client: BackendAPIClient | None = None,
        embedder: ProfileEmbedder | None = None,
        vector_search_client: VectorSearchClient | None = None,
    ):
        self.backend_client = backend_client or get_backend_client()
        self.embedder = embedder or get_embedder()
        self.vector_search_client = vector_search_client or get_vector_search_client()

    async def get_user_profile(self, user_id: int) -> dict | None:
        """ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ ì¡°íšŒ (skills, jobs, introduction)"""
        return await self.backend_client.get_user_profile(user_id)

    async def get_user_profile_text(self, user_id: int) -> str | None:
        """ì‚¬ìš©ì í”„ë¡œí•„ í…ìŠ¤íŠ¸ ìƒì„±"""
        profile = await self.backend_client.get_user_profile(user_id)
        return self._build_profile_text(profile)

    def _build_profile_text(self, profile: dict[str, Any] | None) -> str | None:
        """í”„ë¡œí•„ ë°ì´í„°ë¥¼ ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if not profile:
            return None

        # skills, jobs ë°ì´í„° ì •ì œ (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ ë“± ì²˜ë¦¬)
        skills = self._to_set(profile.get("skills", []))
        jobs = self._to_set(profile.get("jobs", []))
        introduction = profile.get("introduction", "")

        parts = []
        if jobs:
            parts.append(f"ì§ë¬´: {', '.join(jobs)}")
        if skills:
            parts.append(f"ê¸°ìˆ ìŠ¤íƒ: {', '.join(skills)}")
        if introduction:
            parts.append(f"ìê¸°ì†Œê°œ: {introduction}")

        return ". ".join(parts) if parts else None

    def _to_set(self, items: Any) -> set[str]:
        """ë¦¬ìŠ¤íŠ¸ ë‚´ë¶€ì˜ ë”•ì…”ë„ˆë¦¬ë‚˜ ë¬¸ìì—´ì„ ë¬¸ìì—´ ì§‘í•©ìœ¼ë¡œ ë³€í™˜"""
        if not items:
            return set()
        result = set()
        for item in items:
            if isinstance(item, dict):
                # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° "name" í•„ë“œê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                name = item.get("name") or item.get("job_name") or item.get("skill_name")
                result.add(str(name) if name else str(item))
            else:
                result.add(str(item))
        return result

    # ========== í—¬í¼ ë©”ì„œë“œ ==========

    def _candidate_to_mentor(
        self,
        cand: dict[str, Any],
        user_skills: set[str],
        user_jobs: set[str],
    ) -> MentorCandidate:
        """API ì‘ë‹µ dictë¥¼ MentorCandidateë¡œ ë³€í™˜"""
        # í•„ë“œ ë§¤í•‘ (ë°±ì—”ë“œ API ë²„ì „ì— ë”°ë¥¸ ì°¨ì´ ë³´ì •)
        user_id = cand.get("user_id") or cand.get("id")
        if user_id is None:
            logger.warning(f"ë©˜í†  ë°ì´í„°ì— user_idê°€ ì—†ìŠµë‹ˆë‹¤: {cand}")
            user_id = 0

        mentor_skills = self._to_set(cand.get("skills", []))
        mentor_jobs = self._to_set(cand.get("jobs", []))

        # í‰ì  ë° ì‘ë‹µë¥  ì²˜ë¦¬ (ê¸°ë³¸ê°’ ë° ì•ˆì „í•œ ë°˜ì˜¬ë¦¼)
        rating_avg = cand.get("rating_avg")
        if rating_avg is None:
            rating_avg = cand.get("rating_count_avg", 0.0)  # ë°±ì—”ë“œ í•„ë“œëª… ê°€ëŠ¥ì„± ëŒ€ì‘

        response_rate = 0.0
        responded = cand.get("responded_request_count", 0)
        accepted = cand.get("accepted_request_count", 0)
        if responded and responded > 0:
            response_rate = (accepted / responded) * 100

        last_active = cand.get("last_active_at")
        if last_active and hasattr(last_active, "isoformat"):
            last_active = last_active.isoformat()

        return MentorCandidate(
            user_id=int(user_id),
            nickname=cand.get("nickname") or cand.get("name") or "ì´ë¦„ ì—†ìŒ",
            introduction=cand.get("introduction", ""),
            company_name=cand.get("company_name") or cand.get("organization"),
            verified=cand.get("verified", False),
            rating_avg=round(float(rating_avg), 1),
            rating_count=cand.get("rating_count", 0),
            response_rate=round(float(response_rate), 1),
            skills=list(mentor_skills),
            jobs=list(mentor_jobs),
            similarity_score=round(float(cand.get("similarity_score", 0.0)), 4),
            last_active_at=last_active if isinstance(last_active, str) else None,
            _job_matched=bool(user_jobs & mentor_jobs),
            _skill_matched=bool(user_skills & mentor_skills),
        )

    def _filter_candidates(
        self,
        candidates: list[MentorCandidate],
        top_k: int,
    ) -> list[MentorCandidate]:
        """í›„ë³´ í•„í„°ë§ (ì§ë¬´ ìš°ì„ , ê¸°ìˆ ìŠ¤íƒ fallback, ì‘ë‹µë¥  fallback)

        Args:
            candidates: ì „ì²´ í›„ë³´ ë¦¬ìŠ¤íŠ¸ (ì„ë² ë”© ìœ ì‚¬ë„ìˆœìœ¼ë¡œ ì •ë ¬ë¨)
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê°œìˆ˜

        Returns:
            í•„í„°ë§ëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸
        """
        # 1ì°¨ í•„í„°ë§: ì§ë¬´ ì¼ì¹˜
        job_filtered = [c for c in candidates if c._job_matched]

        # 2ì°¨ í•„í„°ë§: ì§ë¬´ ê²°ê³¼ê°€ 5ê°œ ì´í•˜ë©´ ê¸°ìˆ ìŠ¤íƒìœ¼ë¡œ í™•ì¥
        if len(job_filtered) <= MIN_CANDIDATES_FOR_JOB_FILTER:
            skill_filtered = [c for c in candidates if c._skill_matched]

            # ì§ë¬´ ì¼ì¹˜ ìš°ì„ 
            for c in job_filtered:
                c.filter_type = "job"
            for c in skill_filtered:
                if c.filter_type is None:
                    c.filter_type = "skill"

            # ì§ë¬´ ì¼ì¹˜ ë¨¼ì €, ê¸°ìˆ ìŠ¤íƒ ì¼ì¹˜ ê·¸ ë‹¤ìŒ
            job_filtered_set = set(c.user_id for c in job_filtered)
            filtered = job_filtered + [c for c in skill_filtered if c.user_id not in job_filtered_set]
        else:
            for c in job_filtered:
                c.filter_type = "job"
            filtered = job_filtered

        # 3ì°¨ í•„í„°ë§: ê²°ê³¼ê°€ ë¶€ì¡±í•  ê²½ìš° ì‘ë‹µë¥  ë†’ì€ ìˆœìœ¼ë¡œ í™•ì¥ (Fallback)
        if len(filtered) < top_k:
            filtered_set = set(c.user_id for c in filtered)

            # ì´ë¯¸ í¬í•¨ëœ ë©˜í†  ì œì™¸í•œ ë‚˜ë¨¸ì§€ë¥¼ ì‘ë‹µë¥  ìˆœìœ¼ë¡œ ì •ë ¬
            fallback_candidates = [c for c in candidates if c.user_id not in filtered_set]

            # ì‘ë‹µë¥ (response_rate) ë‚´ë¦¼ì°¨ìˆœ, ê·¸ë‹¤ìŒ ìœ ì‚¬ë„ ìˆœ
            fallback_candidates.sort(key=lambda x: (x.response_rate, x.similarity_score), reverse=True)

            for c in fallback_candidates:
                c.filter_type = "response_rate"
                filtered.append(c)
                if len(filtered) >= top_k:
                    break

        return filtered[:top_k]

    async def verify_mentor_ground_truth(
        self,
        mentor_user_id: int,
        top_k: int = 3,
    ) -> dict[str, Any]:
        """
        ê°œë³„ ë©˜í† ì— ëŒ€í•œ Silver Ground Truth ê²€ì¦

        ë©˜í†  í”„ë¡œí•„ì„ ì¡ì‹œì»¤ë¡œ ë³€í™˜ â†’ ì¶”ì²œ ì‹¤í–‰ â†’ ìê¸° ìì‹ ì´ Top-Kì— ìˆëŠ”ì§€ í™•ì¸

        Returns:
            {"is_hit": bool, "rank": int | None}
        """
        # ë©˜í†  ìƒì„¸ ì •ë³´ ì¡°íšŒ (í˜„ì§ì API ì‚¬ìš©)
        profile = await self.backend_client.get_expert_details(mentor_user_id)
        if not profile:
            return {"is_hit": False, "rank": None}

        parts = []
        if profile["jobs"]:
            parts.append(f"ì§ë¬´: {', '.join(profile['jobs'])}")
        if profile["skills"]:
            parts.append(f"ê¸°ìˆ ìŠ¤íƒ: {', '.join(profile['skills'])}")
        if profile["introduction"]:
            parts.append(f"ìê¸°ì†Œê°œ: {profile['introduction']}")

        if not parts:
            return {"is_hit": False, "rank": None}

        jobseeker_text = ". ".join(parts)

        # ì„ë² ë”© ìƒì„± ë° ê²€ìƒ‰
        query_embedding = self.embedder.embed_text(jobseeker_text)
        embedding_list = query_embedding.tolist()

        candidates = await self.vector_search_client.search_similar_experts(
            query_embedding=embedding_list,
            top_n=top_k,
        )

        recommended_ids = [c["user_id"] for c in candidates]

        is_hit = mentor_user_id in recommended_ids
        rank = recommended_ids.index(mentor_user_id) + 1 if is_hit else None

        return {"is_hit": is_hit, "rank": rank}

    async def recommend_mentors(
        self,
        user_id: int,
        top_k: int = 3,
        only_verified: bool = False,
        include_gt: bool = False,
    ) -> list[dict[str, Any]]:
        """
        í•„í„°ë§ + ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ë©˜í†  ì¶”ì²œ

        1ì°¨: ì§ë¬´ ì¼ì¹˜ í•„í„°ë§
        2ì°¨: ì§ë¬´ ì¼ì¹˜ ê²°ê³¼ê°€ 5ê°œ ì´í•˜ë©´ ê¸°ìˆ ìŠ¤íƒ í•˜ë‚˜ ì´ìƒ ì¼ì¹˜ë¡œ í™•ì¥
        ì •ë ¬: ì„ë² ë”© ìœ ì‚¬ë„

        Args:
            user_id: ì¶”ì²œ ëŒ€ìƒ ì‚¬ìš©ì ID
            top_k: ì¶”ì²œí•  ë©˜í†  ìˆ˜
            only_verified: ì¸ì¦ëœ ë©˜í† ë§Œ ì¶”ì²œí• ì§€ ì—¬ë¶€
            include_gt: ê° ë©˜í† ì— ëŒ€í•œ Ground Truth ê²€ì¦ í¬í•¨ ì—¬ë¶€

        Returns:
            ì¶”ì²œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ë©˜í†  ì •ë³´ + ì„ë² ë”© ìœ ì‚¬ë„)
        """
        # 1) ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ
        try:
            with tracer.start_as_current_span("get_user_profile"):
                user_profile = await self.get_user_profile(user_id)
        except Exception as e:
            logger.warning(f"ìœ ì € í”„ë¡œí•„ ì¡°íšŒ ì‹¤íŒ¨ (user_id={user_id}): {e} â†’ fallback ì „í™˜")
            return []

        if not user_profile:
            logger.warning(f"User {user_id} not found")
            return []

        user_skills = self._to_set(user_profile.get("skills", []))
        user_jobs = self._to_set(user_profile.get("jobs", []))
        introduction = user_profile.get("introduction", "")

        # 2) í”„ë¡œí•„ í…ìŠ¤íŠ¸ ìƒì„± (ì„ë² ë”©ìš©)
        profile_text = await self.get_user_profile_text(user_id)
        if not profile_text:
            logger.warning(
                f"User {user_id} has insufficient profile data "
                f"(jobs: {len(user_jobs)}, skills: {len(user_skills)}, intro: {bool(introduction)})"
            )
            return []

        # 3) ì„ë² ë”© ìƒì„±
        with tracer.start_as_current_span("embed_user_profile"):
            user_embedding = self.embedder.embed_text(profile_text, is_query=True)
            embedding_list = user_embedding.tolist()

        # 4) ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (ì§ì ‘ DB)
        candidate_limit = max(top_k * 5, 30)

        with tracer.start_as_current_span("vector_search_db"):
            search_results = await self.vector_search_client.search_similar_experts(
                query_embedding=embedding_list,
                top_n=candidate_limit,
                exclude_user_id=user_id,
            )

        # [ì¶”ê°€] ê²€ìƒ‰ ê²°ê³¼ê°€ ì „í˜€ ì—†ëŠ” ê²½ìš°, DB ì„ë² ë”© ìƒíƒœ í™•ì¸
        if not search_results:
            status = await self.vector_search_client.get_embedding_status()
            if status["total_count"] > 0 and status["embedded_count"] < status["total_count"]:
                missing = status["total_count"] - status["embedded_count"]
                logger.warning(
                    f"ğŸš¨ DBì— ì „ë¬¸ê°€ {status['total_count']}ëª… ì¤‘ {missing}ëª…ì˜ ì„ë² ë”©ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ìë™ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                )
                # ì´ ì •ë³´ëŠ” ìƒìœ„ ì»¨íŠ¸ë¡¤ëŸ¬ì—ì„œ ì‚¬ìš©í•˜ì—¬ Background Taskë¥¼ íŠ¸ë¦¬ê±°í•  ìˆ˜ ìˆìŒ
                # í•˜ì§€ë§Œ retrieval ìˆ˜ì¤€ì—ì„œëŠ” ë¡œê¹…ê³¼ ê²°ê³¼ ì—†ìŒ ë°˜í™˜ì— ì§‘ì¤‘
            elif status["total_count"] == 0:
                logger.warning("ğŸš¨ DBì— ì „ë¬¸ê°€ ë°ì´í„°ê°€ ì „í˜€ ì—†ìŠµë‹ˆë‹¤.")

        # 5) ê²€ìƒ‰ ê²°ê³¼ì— ë©˜í†  ìƒì„¸ ì •ë³´ ê²°í•© (ë³‘ë ¬ë¡œ ìƒìœ„ í›„ë³´ë“¤ì˜ ì •ë³´ë§Œ ê°€ì ¸ì˜´)
        import asyncio

        experts_map = {}
        semaphore = asyncio.Semaphore(10)  # 10ê°œ ë³‘ë ¬

        async def _fetch_expert(uid):
            async with semaphore:
                details = await self.backend_client.get_expert_details(uid)
                return uid, details

        fetch_tasks = [_fetch_expert(sr["user_id"]) for sr in search_results]

        with tracer.start_as_current_span("fetch_expert_details_batch"):
            try:
                fetch_results = await asyncio.gather(*fetch_tasks)
                experts_map = {uid: details for uid, details in fetch_results if details}
            except Exception as e:
                logger.warning(f"ë©˜í†  ìƒì„¸ ì •ë³´ ì·¨í•© ì‹¤íŒ¨: {e}")

        raw_candidates = []
        for sr in search_results:
            uid = sr["user_id"]
            expert_data = experts_map.get(uid, {})
            raw_candidates.append(
                {
                    **expert_data,
                    "user_id": uid,
                    "similarity_score": sr["similarity_score"],
                }
            )

        # 6) í›„ë³´ ë°ì´í„° ë³€í™˜
        all_candidates = [self._candidate_to_mentor(c, user_skills, user_jobs) for c in raw_candidates]

        # 7) í•„í„°ë§ ë° Top-K ì„ íƒ
        top_candidates = self._filter_candidates(all_candidates, top_k)

        # Ground Truth ê²€ì¦ (ì˜µì…˜)
        if include_gt:
            for candidate in top_candidates:
                gt_result = await self.verify_mentor_ground_truth(
                    mentor_user_id=candidate.user_id,
                    top_k=top_k,
                )
                candidate.ground_truth = gt_result

        # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return [c.to_dict() for c in top_candidates]

    async def fallback_by_response_rate(
        self,
        top_k: int = 3,
    ) -> list[dict[str, Any]]:
        """
        Fallback: ìœ ì‚¬ë„ ì¶”ì²œ ì‹¤íŒ¨ ì‹œ ì‘ë‹µë¥  ë†’ì€ ìˆœìœ¼ë¡œ ë©˜í†  ë°˜í™˜

        ìœ ì € í”„ë¡œí•„ ì¡°íšŒ ë¶ˆê°€(401 ë“±) ë˜ëŠ” ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ ì‚¬ìš©
        GET /api/v1/experts ë¡œ ì „ì²´ ë©˜í†  ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ ì‘ë‹µë¥  ìˆœìœ¼ë¡œ ì •ë ¬
        """
        try:
            raw_experts = await self.backend_client.get_experts()

            if not raw_experts:
                logger.warning("Fallback: ë©˜í†  í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
                return []

            # MentorCandidateë¡œ ë³€í™˜ (ìœ ì € ìŠ¤í‚¬/ì¡ ì—†ì´)
            candidates = []
            for c in raw_experts:
                try:
                    candidates.append(self._candidate_to_mentor(c, user_skills=set(), user_jobs=set()))
                except Exception as e:
                    logger.warning(f"ë©˜í†  ë³€í™˜ ì‹¤íŒ¨ (user_id={c.get('user_id')}): {e}")
                    continue

            # ì‘ë‹µë¥  ë‚´ë¦¼ì°¨ìˆœ â†’ í‰ì  ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            candidates.sort(
                key=lambda x: (x.response_rate, x.rating_avg),
                reverse=True,
            )

            for c in candidates:
                c.filter_type = "fallback_response_rate"

            top = candidates[:top_k]
            logger.info(
                f"Fallback ì™„ë£Œ: ì‘ë‹µë¥  ê¸°ë°˜ {len(top)}ëª… ì¶”ì²œ "
                f"(top response_rate={top[0].response_rate if top else 0}%)"
            )
            return [c.to_dict() for c in top]

        except Exception as e:
            logger.error(f"Fallback ì‹¤íŒ¨: {e}")
            return []

    async def recommend_experts(
        self,
        query_text: str,
        top_k: int = 5,
        only_verified: bool = False,
    ) -> list[dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ì§ì ‘ ë©˜í†  ê²€ìƒ‰ (ë¡œì»¬ DB ê¸°ë°˜)
        """
        query_embedding = self.embedder.embed_text(query_text, is_query=True)
        embedding_list = query_embedding.tolist()

        # ë¡œì»¬ DBì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
        experts = await self.vector_search_client.search_similar_experts(
            query_embedding=embedding_list,
            top_n=top_k,
        )

        return [
            {
                "user_id": e["user_id"],
                "nickname": f"Mentor {e['user_id']}",
                "similarity_score": round(float(e["similarity_score"]), 4),
            }
            for e in experts
        ]

    async def update_expert_embedding(self, user_id: int) -> bool:
        """íŠ¹ì • ë©˜í† ì˜ ì„ë² ë”© ì—…ë°ì´íŠ¸ (ë°±ì—”ë“œ APIë¥¼ í†µí•´ ì €ì¥)"""
        # ë©˜í†  ìƒì„¸ ì •ë³´ ì¡°íšŒ (í˜„ì§ì API ì‚¬ìš©)
        expert_details = await self.backend_client.get_expert_details(user_id)
        if not expert_details:
            logger.warning(f"Mentor {user_id} not found to embed")
            return False

        profile_text = self._build_profile_text(expert_details)
        if not profile_text:
            logger.warning(f"Mentor {user_id} has no profile data to embed")
            return False

        embedding = self.embedder.embed_text(profile_text, is_query=False)
        embedding_list = embedding.tolist()

        # ë°±ì—”ë“œ APIë¥¼ í†µí•´ ì €ì¥ (ë°±ì—”ë“œì—ì„œ DB ì—…ë°ì´íŠ¸ ì²˜ë¦¬)
        try:
            success = await self.backend_client.save_embedding(user_id, embedding_list)
            if success:
                logger.info(f"Updated embedding for mentor {user_id} via backend API")
            return success
        except Exception as e:
            logger.error(f"Failed to save embedding to backend for user {user_id}: {e}")
            return False

    async def compute_embedding(self, user_id: int) -> dict[str, Any] | None:
        """
        ì‚¬ìš©ì í”„ë¡œí•„ ì„ë² ë”© ê³„ì‚°

        Args:
            user_id: ì‚¬ìš©ì ID

        Returns:
            {"user_id": int, "embedding": list[float]} or None
        """
        profile_text = await self.get_user_profile_text(user_id)
        if not profile_text:
            logger.warning(f"User {user_id} has no profile text")
            return None

        embedding = self.embedder.embed_text(profile_text, is_query=False)
        embedding_list = embedding.tolist()

        logger.debug(f"Computed embedding for user {user_id}, dim={len(embedding_list)}")

        return {
            "user_id": user_id,
            "embedding": embedding_list,
        }

    async def update_all_expert_embeddings(self) -> int:
        """
        ëª¨ë“  ë©˜í†  ì„ë² ë”© ì¼ê´„ ì—…ë°ì´íŠ¸ (Batch ì²˜ë¦¬ ìµœì í™”)
        - 1ë‹¨ê³„: ë°±ì—”ë“œ APIì—ì„œ ë©˜í†  ëª©ë¡ì„ í˜ì´ì§€ ë‹¨ìœ„(Pagination)ë¡œ ê°€ì ¸ì˜´
        - 2ë‹¨ê³„: ê°€ì ¸ì˜¨ í˜ì´ì§€ ë‚´ì˜ ëª¨ë“  í”„ë¡œí•„ í…ìŠ¤íŠ¸ë¥¼ í•œêº¼ë²ˆì— ì„ë² ë”© (embed_texts)
        - 3ë‹¨ê³„: ë°±ì—”ë“œ APIë¥¼ í†µí•´ ì¼ê´„ ì—…ë°ì´íŠ¸ ìš”ì²­
        """
        import asyncio

        logger.info("ğŸš€ ì‹œì‘: ë©˜í†  ì„ë² ë”© ì¼ê´„ ì—…ë°ì´íŠ¸ (Batch ëª¨ë“œ)")

        updated_total = 0
        cursor = None
        page_num = 1

        try:
            while True:
                # ì§„í–‰ ìƒí™© ì¶œë ¥ (10í˜ì´ì§€ë§ˆë‹¤)
                if page_num % 10 == 0 or page_num == 1:
                    logger.info(f"â³ {page_num}í˜ì´ì§€ ì§„í–‰ ì¤‘... (í˜„ì¬ê¹Œì§€ ëˆ„ì  ì—…ë°ì´íŠ¸: {updated_total}ëª…)")

                # 1. ë°±ì—”ë“œì—ì„œ ì „ë¬¸ê°€ ëª©ë¡ í•œ í˜ì´ì§€ë§Œ ê°€ì ¸ì˜¤ê¸° (ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¦ëŒ€)
                experts, cursor, has_more = await self.backend_client.get_experts_page(cursor=cursor, size=500)
                if not experts:
                    break

                # 2. ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
                valid_experts = []
                texts_to_embed = []
                for expert in experts:
                    user_id = expert.get("user_id")
                    if not user_id:
                        continue

                    profile_text = self._build_profile_text(expert)
                    if profile_text:
                        valid_experts.append(expert)
                        texts_to_embed.append(profile_text)

                if texts_to_embed:
                    # 3. ì¼ê´„ ì„ë² ë”© ìƒì„± (Batch Embedding)
                    embeddings = self.embedder.embed_texts(texts_to_embed)

                    # 4. ë¡œì»¬ DB ë° ë°±ì—”ë“œ ì €ì¥ (ë³‘ë ¬ ì²˜ë¦¬)
                    semaphore = asyncio.Semaphore(10)

                    async def _save_task(expert_data, embedding_arr):
                        async with semaphore:
                            uid = expert_data["user_id"]
                            emb_list = embedding_arr.tolist()
                            try:
                                # ë°±ì—”ë“œ APIë¥¼ í†µí•´ ì €ì¥ ìš”ì²­ (ë°±ì—”ë“œê°€ DB ì—…ë°ì´íŠ¸ ë‹´ë‹¹)
                                return await self.backend_client.save_embedding(uid, emb_list)
                            except Exception:
                                return False

                    save_tasks = [_save_task(valid_experts[i], embeddings[i]) for i in range(len(valid_experts))]

                    results = await asyncio.gather(*save_tasks)
                    page_updated = sum(1 for r in results if r)
                    updated_total += page_updated

                    logger.info(f"ğŸ“¦ í˜ì´ì§€ {page_num} ì™„ë£Œ: {page_updated}ëª… ì—…ë°ì´íŠ¸ (ëˆ„ì : {updated_total}ëª…)")

                if not has_more:
                    break
                page_num += 1

            logger.info(f"âœ… ì¼ê´„ ì—…ë°ì´íŠ¸ ìµœì¢… ì™„ë£Œ: ì´ {updated_total}ëª…")
            return updated_total

        except Exception as e:
            logger.error(f"âŒ ì¼ê´„ ì—…ë°ì´íŠ¸ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return updated_total

    async def evaluate_silver_ground_truth(
        self,
        sample_size: int | None = None,
    ) -> dict[str, Any]:
        """
        Silver Ground Truth í‰ê°€

        ë©˜í†  í”„ë¡œí•„ì„ ì¡ì‹œì»¤ í”„ë¡œí•„ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ì²œ ê²°ê³¼ì—
        ì›ë³¸ ë©˜í† ê°€ í¬í•¨ë˜ëŠ”ì§€ ê²€ì¦

        í‰ê°€ ì§€í‘œ:
        - Hit Rate @ K (K=1,3,5,10): Top-Kì— ì •ë‹µ í¬í•¨ ë¹„ìœ¨
        - MRR (Mean Reciprocal Rank): ì •ë‹µ ìˆœìœ„ì˜ ì—­ìˆ˜ í‰ê· 

        Args:
            sample_size: í‰ê°€í•  ìƒ˜í”Œ ìˆ˜ (Noneì´ë©´ ì „ì²´)

        Returns:
            í‰ê°€ ê²°ê³¼ (hit_at_1/3/5/10, mrr, total, details)
        """
        # ì „ì²´ ë©˜í†  ID ê°€ì ¸ì˜¤ê¸°
        expert_ids = await self.backend_client.get_expert_ids()

        # ì‹¤ì‹œê°„ ìš”ì²­ ì‹œ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ê¸°ë³¸ ìƒ˜í”Œ ì‚¬ì´ì¦ˆ ì œí•œ
        if sample_size is None:
            sample_size = 5

        if sample_size:
            expert_ids = expert_ids[:sample_size]

        if not expert_ids:
            return {
                "hit_at_1": 0.0,
                "hit_at_3": 0.0,
                "hit_at_5": 0.0,
                "hit_at_10": 0.0,
                "mrr": 0.0,
                "total": 0,
                "details": [],
            }

        # ê° Kê°’ì— ëŒ€í•œ Hit ì¹´ìš´íŠ¸
        hits = {1: 0, 3: 0, 5: 0, 10: 0}
        reciprocal_ranks = []
        details = []

        for gt_user_id in expert_ids:
            # ë©˜í†  ìƒì„¸ ì •ë³´ ì¡°íšŒ (í˜„ì§ì API ì‚¬ìš©)
            profile = await self.backend_client.get_expert_details(gt_user_id)
            if not profile:
                continue

            parts = []
            if profile["jobs"]:
                parts.append(f"ì§ë¬´: {', '.join(profile['jobs'])}")
            if profile["skills"]:
                parts.append(f"ê¸°ìˆ ìŠ¤íƒ: {', '.join(profile['skills'])}")
            if profile["introduction"]:
                parts.append(f"ìê¸°ì†Œê°œ: {profile['introduction']}")

            if not parts:
                continue

            jobseeker_text = ". ".join(parts)

            # ì„ë² ë”© ìƒì„± ë° Top-10 ê²€ìƒ‰
            query_embedding = self.embedder.embed_text(jobseeker_text)
            embedding_list = query_embedding.tolist()

            candidates = await self.vector_search_client.search_similar_experts(
                query_embedding=embedding_list,
                top_n=10,
            )

            recommended_ids = [c["user_id"] for c in candidates]

            # Hit íŒì • ë° ìˆœìœ„ í™•ì¸
            if gt_user_id in recommended_ids:
                rank = recommended_ids.index(gt_user_id) + 1
                reciprocal_ranks.append(1.0 / rank)

                # ê° Kì— ëŒ€í•´ Hit ì¹´ìš´íŠ¸
                for k in [1, 3, 5, 10]:
                    if rank <= k:
                        hits[k] += 1
            else:
                rank = None
                reciprocal_ranks.append(0.0)

            details.append(
                {
                    "gt_user_id": gt_user_id,
                    "is_hit": rank is not None,
                    "rank": rank,
                    "recommended_ids": recommended_ids,
                }
            )

        total = len(reciprocal_ranks)

        # Hit Rate @ K ê³„ì‚°
        hit_at_1 = (hits[1] / total * 100) if total > 0 else 0.0
        hit_at_3 = (hits[3] / total * 100) if total > 0 else 0.0
        hit_at_5 = (hits[5] / total * 100) if total > 0 else 0.0
        hit_at_10 = (hits[10] / total * 100) if total > 0 else 0.0

        # MRR ê³„ì‚°
        mrr = sum(reciprocal_ranks) / total if total > 0 else 0.0

        return {
            "hit_at_1": round(hit_at_1, 2),
            "hit_at_3": round(hit_at_3, 2),
            "hit_at_5": round(hit_at_5, 2),
            "hit_at_10": round(hit_at_10, 2),
            "mrr": round(mrr, 4),
            "total": total,
            "details": details,
        }
